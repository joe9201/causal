{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "from causallearn.utils.GraphUtils import GraphUtils\n",
    "from causallearn.search.ConstraintBased.FCI import fci\n",
    "from causallearn.utils.cit import fisherz\n",
    "from causallearn.search.ScoreBased.GES import ges\n",
    "from causallearn.search.FCMBased import lingam\n",
    "from causallearn.search.FCMBased.lingam.utils import make_dot\n",
    "from dowhy import CausalModel\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import matplotlib.image as mpimg\n",
    "import pydot\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path ='data/student-por_raw.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['G_avg'] = df[['G1', 'G2', 'G3']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.copy()\n",
    "columns_to_keep = ['absences', 'failures', 'internet', 'higher', 'Medu', 'health', 'famsup', 'Pstatus', 'famrel', 'schoolsup', 'G_avg', 'paid', 'studytime']\n",
    "df_filtered = df_filtered[columns_to_keep]\n",
    "df_encoded = pd.get_dummies(df_filtered, columns=['internet', 'higher', 'famsup', 'paid'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_map = {'Pstatus': {'A': 1, 'T': 2},\n",
    "               'famrel': {1: 1, 2: 2, 3: 3, 4: 4, 5: 5},  # Assuming 1-5 scale\n",
    "               'schoolsup': {'no': 0, 'yes': 1},\n",
    "               'health': {1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}  # Assuming 1-5 scale\n",
    "\n",
    "for col, mapping in ordinal_map.items():\n",
    "    df_encoded[col] = df_encoded[col].map(mapping)\n",
    "    \n",
    "df_encoded = df_encoded * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f'{col}' for col in df_encoded.columns]\n",
    "encoded_feature_names = df_encoded.columns.tolist()\n",
    "data = df_encoded.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_graph(graph, labels, filename):\n",
    "    pyd = GraphUtils.to_pydot(graph, labels=labels)\n",
    "    img = mpimg.imread(io.BytesIO(pyd.create_png(f=\"png\")), format='png')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.savefig(filename, format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_pc = pc(data, alpha=0.1, labels=df_encoded.columns.tolist())\n",
    "plot_and_save_graph(cg_pc.G, labels, 'pc_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_G = nx.DiGraph()\n",
    "for node in cg_pc.G.nodes:\n",
    "    PC_G.add_node(node.get_name())\n",
    "\n",
    "for i in range(len(cg_pc.G.graph)):\n",
    "    for j in range(len(cg_pc.G.graph)):\n",
    "        if cg_pc.G.graph[i, j] > 0:  # Check for a directed edge\n",
    "            PC_G.add_edge(cg_pc.G.nodes[i].get_name(), cg_pc.G.nodes[j].get_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_feature_map = dict(zip(labels, df_encoded.columns))\n",
    "nx.set_node_attributes(PC_G, label_to_feature_map, 'feature_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_G = nx.relabel_nodes(PC_G, label_to_feature_map)\n",
    "print(\"Node labels in the graph:\", PC_G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_names = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13']\n",
    "feature_names = ['absences', 'failures', 'Medu', 'health', 'Pstatus', 'famrel',\n",
    "       'schoolsup', 'G_avg', 'studytime', 'internet_yes', 'higher_yes',\n",
    "       'famsup_yes', 'paid_yes']\n",
    "\n",
    "node_to_feature_mapping = {node: feature for node, feature in zip(node_names, feature_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CausalModel(data=df_encoded, treatment='X1', outcome='X9', graph=PC_G)\n",
    "\n",
    "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "print(identified_estimand)\n",
    "\n",
    "estimate = model.estimate_effect(\n",
    "        identified_estimand,\n",
    "        method_name=\"backdoor.linear_regression\",\n",
    "        control_value=0,\n",
    "        treatment_value=1,\n",
    "        confidence_intervals=True,\n",
    "        test_significance=True\n",
    "    )\n",
    "\n",
    "print(\"Causal Estimate is \" + str(estimate.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_fci = fci(data, alpha=0.1, labels=df_encoded.columns.tolist(), indep_test=fisherz, stable=True, uc_rule=0)\n",
    "plot_and_save_graph(cg_fci[0], labels, 'fci_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fci_graph = cg_fci[0] \n",
    "\n",
    "# Convert to networkx graph \n",
    "G_fci = nx.DiGraph()\n",
    "# Add all nodes from the causallearn graph\n",
    "for node in fci_graph.nodes:\n",
    "    G_fci.add_node(node.get_name())\n",
    "\n",
    "# Add edges from the causallearn graph\n",
    "for i in range(len(fci_graph.graph)):\n",
    "    for j in range(len(fci_graph.graph)):\n",
    "        if fci_graph.graph[i, j] > 0:  # Check for a directed edge\n",
    "            G_fci.add_edge(fci_graph.nodes[i].get_name(), fci_graph.nodes[j].get_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CausalModel(data=df_encoded, treatment='X1', outcome='X9', graph=G_fci)\n",
    "\n",
    "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "print(identified_estimand)\n",
    "\n",
    "estimate = model.estimate_effect(\n",
    "        identified_estimand,\n",
    "        method_name=\"backdoor.linear_regression\",\n",
    "        control_value=0,\n",
    "        treatment_value=1,\n",
    "        confidence_intervals=True,\n",
    "        test_significance=True\n",
    "    )\n",
    "\n",
    "print(\"Causal Estimate is \" + str(estimate.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_ges = ges(data)\n",
    "plot_and_save_graph(record_ges['G'], labels, 'ges_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ges_graph = record_ges['G'] \n",
    "\n",
    "# Convert to networkx graph \n",
    "G_ges = nx.DiGraph()\n",
    "# Add all nodes from the causallearn graph\n",
    "for node in ges_graph.nodes:\n",
    "    G_ges.add_node(node.get_name())\n",
    "\n",
    "# Add edges from the causallearn graph\n",
    "for i in range(len(ges_graph.graph)):\n",
    "    for j in range(len(ges_graph.graph)):\n",
    "        if ges_graph.graph[i, j] > 0:  # Check for a directed edge\n",
    "            G_ges.add_edge(ges_graph.nodes[i].get_name(), ges_graph.nodes[j].get_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CausalModel(data=df_data, treatment='X1', outcome='X9', graph=G_ges)\n",
    "\n",
    "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "print(identified_estimand)\n",
    "\n",
    "estimate = model.estimate_effect(\n",
    "        identified_estimand,\n",
    "        method_name=\"backdoor.linear_regression\",\n",
    "        control_value=0,\n",
    "        treatment_value=1,\n",
    "        confidence_intervals=True,\n",
    "        test_significance=True\n",
    "    )\n",
    "\n",
    "print(\"Causal Estimate is \" + str(estimate.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lingam = lingam.ICALiNGAM()\n",
    "model_lingam.fit(data)\n",
    "digraph = make_dot(model_lingam.adjacency_matrix_, labels=labels)\n",
    "graph_dot_string = digraph.source\n",
    "digraph.render('lingam_graph', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pydot graph object (This is now a Digraph object)\n",
    "digraph = make_dot(model_lingam.adjacency_matrix_, labels=labels)\n",
    "\n",
    "# Get DOT string representation from Digraph object\n",
    "graph_dot_string = digraph.source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(data, columns=labels)\n",
    "model = CausalModel(data=df_data, treatment='absences', outcome='G_avg', graph=graph_dot_string)\n",
    "\n",
    "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "print(identified_estimand)\n",
    "\n",
    "estimate = model.estimate_effect(identified_estimand,\n",
    "                                 method_name=\"backdoor.linear_regression\",\n",
    "                                 control_value=0,\n",
    "                                 treatment_value=1,\n",
    "                                 confidence_intervals=True,\n",
    "                                 test_significance=True)\n",
    "print(\"Causal Estimate is \" + str(estimate.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of an Evaluation Function\n",
    "The evaluation function should be tailored to your specific needs, but a generic approach could involve comparing the inferred graph against a known ground truth or evaluating how well the causal model explains the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def some_evaluation_function(graph):\n",
    "    # Placeholder for an actual evaluation function\n",
    "    # Example: compare against ground truth or use a scoring metric\n",
    "    # return np.random.rand()  # Replace with actual evaluation logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_true = nx.DiGraph()\n",
    "\n",
    "nodes = {\n",
    "    \"G_avg\": {\"pos\": \"0.176, -0.450\"},\n",
    "    \"Medu\": {\"pos\": \"-0.630,0.589\"},\n",
    "    \"Pstatus\": {\"pos\": \"-1.493,-0.841\"},\n",
    "    \"absences\": {\"pos\": \"-1.468,0.878\"},\n",
    "    \"address\": {\"pos\": \"-1.971,1.405\"},\n",
    "    \"failures\": {\"pos\": \"1.150,1.680\"},\n",
    "    \"famrel\": {\"pos\": \"-2.149,-1.148\"},\n",
    "    \"famsup\": {\"pos\": \"-1.049,-0.302\"},\n",
    "    \"health\": {\"pos\": \"-0.688,0.017\"},\n",
    "    \"higher\": {\"pos\": \"0.155,0.551\"},\n",
    "    \"internet\": {\"pos\": \"0.647,1.138\"},\n",
    "    \"paid\": {\"pos\": \"-0.463,-1.386\"},\n",
    "    \"schoolsup\": {\"pos\": \"1.035,0.158\"},\n",
    "    \"studytime\": {\"pos\": \"0.302,-1.504\"}\n",
    "}\n",
    "\n",
    "for node, pos in nodes.items():\n",
    "    G_true.add_node(node, pos=pos)\n",
    "\n",
    "G_true.add_edges_from([\n",
    "    (\"Medu\", \"G_avg\"),\n",
    "    (\"Medu\", \"absences\"),\n",
    "    (\"Medu\", \"higher\"),\n",
    "    (\"Pstatus\", \"G_avg\"),\n",
    "    (\"Pstatus\", \"absences\"),\n",
    "    (\"Pstatus\", \"famrel\"),\n",
    "    (\"address\", \"absences\"),\n",
    "    (\"failures\", \"G_avg\"),\n",
    "    (\"failures\", \"absences\"),\n",
    "    (\"famsup\", \"G_avg\"),\n",
    "    (\"famsup\", \"absences\"),\n",
    "    (\"health\", \"G_avg\"),\n",
    "    (\"health\", \"absences\"),\n",
    "    (\"higher\", \"G_avg\"),\n",
    "    (\"internet\", \"G_avg\"),\n",
    "    (\"internet\", \"absences\"),\n",
    "    (\"paid\", \"G_avg\"),\n",
    "    (\"schoolsup\", \"G_avg\"),\n",
    "    (\"studytime\", \"G_avg\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G_true)\n",
    "nx.draw(G_true, pos, with_labels=True, node_size=2000, node_color='skyblue', font_size=10, font_color='black', font_weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def evaluate_graph(inferred_graph, ground_truth_graph):\n",
    "    # Convert graphs to adjacency matrices\n",
    "    inferred_adj = nx.adjacency_matrix(inferred_graph).todense()\n",
    "    ground_truth_adj = nx.adjacency_matrix(ground_truth_graph).todense()\n",
    "    \n",
    "    # Calculate evaluation metrics (precision, recall, F1-score)\n",
    "    tp = np.sum(np.logical_and(inferred_adj == 1, ground_truth_adj == 1))\n",
    "    fp = np.sum(np.logical_and(inferred_adj == 1, ground_truth_adj == 0))\n",
    "    fn = np.sum(np.logical_and(inferred_adj == 0, ground_truth_adj == 1))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision * recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Example usage\n",
    "precision, recall, f1_score = evaluate_graph(inferred_graph, G)\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1-Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alphas = [0.01, 0.05, 0.1]\n",
    "stables = [True, False]\n",
    "uc_rules = [0, 1]\n",
    "\n",
    "best_cg_fci = None\n",
    "best_score = float('inf')\n",
    "\n",
    "for alpha in alphas:\n",
    "    for stable in stables:\n",
    "        for uc_rule in uc_rules:\n",
    "            cg_fci = fci(data, alpha=alpha, indep_test=fisherz, stable=stable, uc_rule=uc_rule)\n",
    "            score = some_evaluation_function(cg_fci[0])  # Define your evaluation function\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_cg_fci = cg_fci\n",
    "\n",
    "# Use best_cg_fci\n",
    "plot_and_save_graph(best_cg_fci[0], labels, 'fci_graph_best.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_cg_pc = None\n",
    "best_f1_score = float('-inf')\n",
    "\n",
    "for alpha in alphas:\n",
    "    cg_pc = pc(data, alpha=alpha)\n",
    "    precision, recall, f1_score = evaluate_graph(cg_pc.G, G)\n",
    "    if f1_score > best_f1_score:\n",
    "        best_f1_score = f1_score\n",
    "        best_cg_pc = cg_pc\n",
    "\n",
    "# Use best_cg_pc\n",
    "plot_and_save_graph(best_cg_pc.G, labels, 'pc_graph_best.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
